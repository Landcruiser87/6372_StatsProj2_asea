---
title: "Health Analysis"
author: "asea"
date: "April 17, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(car)
library(Hmisc)
library(gplots)
library(ggplot2)
library(ROCR)
library(MASS)
library(corrplot)
library(randomForest)
library(epitools)
library(dplyr)
library(glmnet)
```

The national dataset used in this study comes from the 2017 County Health Rankings website. Since each state and county have varying populations, we chose to use the data as a percent of the population. The death rate is the age-adjusted Years of Potential Life Lost rate per 100,000. All variables are continuous so we do not need to be concerned about unbalanced categorical variables.

OBJECTIVE1

We want to model the probability of being obsese (BMI > 30) for a particular variable. The team has decided to use the following variables as the predictors.The variable data represent the percentage of the population for a specifc US county.

Health Variables
- Smokers
- Physically Incactive
- Excesive Drinking
- Frequent Mental Distress
- Frequent Physical Distress
- Diabetic
- Insufficient Sleep

Demographic Type Variables
- Uninsured
- Some College 
- Unemployed
- Severe Housing Problems


EXPLORATORY DATA ANALYSIS

```{r EDA Start}
# import health data
alldata = read.csv("./Data/CHR_Data.csv")

# get initial data
data <- alldata[,-c(1:3,4,14,18:24)]

# show data summary to identify variables with missing data
summary(data)
```

The summary statistics show missing values for Premature_Death_Rate, Unemployed, Uninsured, and Graduation_Rate. We impute the missing data with the median values since some distributions show a little skew when comparing the mean and medians. We will later show the histograms confirm some skew.

```{r EDA Impute}
# impute variables with their medians, prefer medians in the event there is any skew
data$Unemployed <- with(data,impute(Unemployed,median))
data$Uninsured <- with(data,impute(Uninsured,median))
```

EDA-SKEW 

The histograms confirm some skew with Frequent_Mental_Distress, Frequent_Physical_Distress,Uninsured, Unemployed, and Severe_Housing_Problems. There is no concern or need to do anything about the skew since we have a relatively large data set and we are performing a logistic regression. 

```{r EDA Histograms}
# get chosen predictors for EDA
predictors <- data[,-2]

# histogram of chosen predictors
par(mfrow=c(3,4))
for(i in 1:11) {
    hist(predictors[,i], main=names(predictors)[i])
}
```

OUTLIERS (Used SAS, will put screen shots and comments about Cook's D in final paper)

We remove the data for Yuma county in Arizona due to the outlier it creates for unemployment. The county is along the Mexico border and is predominately a farming community with migrant (seasonal) workers. This situation is uncommon and not typical of U.S. counties. We also removed the data for Imperial county in California for the same reasons. It is adjacent to Yuma county.

We remove the data for Bethel, Northwest Arctic and Yukon-Koyukuk counties in Alaska for Severe Housing Problems. There are four factors that contribute to this category. They are housing units that lack complete kitchens, lack complete plumbing facilities, overcrowded, or severely cost burdened. These counties reside in Alaska where the cost to build is beyond what the residents can afford and therefore overcrowding is above normal compared to the rest of the United States. [Nathan Wiltse, Dustin Madden, 2018 Alaska Housing Assessment, Jan 17, 2018, https://www.ahfc.us/download_file/view/5124/853]

```{r Remove Outliers}
# print data before outlier removal
plot(data$Unemployed)
plot(data$Severe_Housing_Problems)

data <- data[!rowSums(data[c(-1:-10,-12)] > 20),] # removed unemployment outliers for migrant farming counties
data <- data[!rowSums(data[c(-1:-11)] > 50),] # removed housing prob outliers for poor Alaska counties

# print data after outlier removal
plot(data$Unemployed)
plot(data$Severe_Housing_Problems)
```

```{r EDA Scatter Plots}
# create obese binary classification where BMI >= 30 is considered Obese, 0 = not obese, 1 = obese
data$Obese_Class <- 1
data[data$Obese < 30, "Obese_Class"] <- 0
data$Obese_Class <- as.factor(as.character(data$Obese_Class))

# -- create new data set with obese_class first --
data2 <- data[,c(13,1,3:12)]

# summary stats by group Obese_Class, to add to SAS Box Plots
t(aggregate(Smokers~Obese_Class,data=data2,summary))
t(aggregate(Physically_Inactive~Obese_Class,data=data2,summary))
t(aggregate(Excessive_Drinking~Obese_Class,data=data2,summary))
t(aggregate(Frequent_Mental_Distress~Obese_Class,data=data2,summary))
t(aggregate(Frequent_Physical_Distress~Obese_Class,data=data2,summary))
t(aggregate(Diabetic~Obese_Class,data=data2,summary))
t(aggregate(Insufficient_Sleep~Obese_Class,data=data2,summary))
t(aggregate(Uninsured~Obese_Class,data=data2,summary))
t(aggregate(Some_College~Obese_Class,data=data2,summary))
t(aggregate(Unemployed~Obese_Class,data=data2,summary))
t(aggregate(Severe_Housing_Problems~Obese_Class,data=data2,summary))

# scatter matrices, with Obese as the colors
pairs(data2[,2:12],col=data$Obese_Class)
```

For the most part, the colored scatter plot matrix tells us our variables should do a decent job with logistic regression based on the color separation seen in the matrix. Strong correlation  is seen between the following:
<ul>
<li>Frequenet_Mental_Distress, Physical_Mental_Distress</li>
</ul>
There's fairly good correlation between the following:
<ul>
<li>Smokers, Frequent_Mental_Distress, Physical_Mental_Distress</li>
<li>Diabetic, Physically_Inactive, Insufficient Sleep, Frequent_Mental_Distress, Frequent_Physical_Distress.</li>
</ul>

We'll review a correlation heatmap to get better insights next.

```{r EDA Heatmap}
# predictor heatmap correlations to examine whether variables are redundant
cor1 <- cor(data2[,2:12])

heatmap.2(cor1,col=redgreen(75), cexRow=.7,cexCol=0.7,
          density.info="none", trace="none", dendrogram=c("both"), 
          symm=F,symkey=T,symbreaks=T, scale="none",key=T)
```

The dendogramed heatmap confirms the strong correlation previously seen with Frequenet_Mental_Distress and Physical_Mental_Distress.


Additional correlation is seen between the following:
<ul>
<li>Unemployed, Insufficient Sleep</li>
<li>Some_College, Excessive_Drinking</li>
<li>Diabetic, Physically_Inactive</li>
<li>Smokers, Frequenet_Mental_Distress, Physical_Mental_Distress</li>
<li>Uninured, Severe_Housing_Problems</li>
</ul>

The correlations identified by the dendogram surprisingly all make practical sense. One would expect to lose sleep if they were unemployed. Drinking being correlated to college makes sense. Diabetic is not uncommon amongst physically incative people. If someone is living in an area with severe housing problems, we might expect they would not be able to afford insurance.

Let's review correlation with ratings seen in a variable correlation heatmap.

```{r EDA CorrPlot}
#Correlation Plot 
cor2 <- cor(data2[,2:12])
df_corr <-corrplot(cor2, type="upper", addCoef.col = "white", number.digits = 2, number.cex = 0.5, method="square", order="hclust", title="Variable Corr Heatmap",tl.srt=45, tl.cex = 0.8)
```

Based on the variable correlation heatmap, the order of correalated variables are:
<ol>
<li>Frequenet_Mental_Distress, Physical_Mental_Distress</li>
<li>Smokers, Frequenet_Physical_Distress</li>
<li>Smokers, Frequenet_Mental_Distress</li>
<li>Diabetic, Physically_Inactive</li>
<li>Frequent_Mental_Distress, Insufficient Sleep</li>
<li>Unemployed, Frequent_Mental_Distress</li>
<li>Unemployed, Frequent_Physical_Distress</li>
<li>Excessive_Drinking, Frequent_Physical_Distress</li>
<li>Excessive_Drinking, Frequent_Mental_Distress</li>
<li>Diabetic, Frequent_Mental_Distress</li>
</ol>

Let's look at the VIFs to confirm the collinear variables.

```{r VIF Check}
# Logistics Regression
glm.vifchk <- glm(Obese_Class ~ ., data = data2, family = binomial(link="logit"))
vif(glm.vifchk)
```

The VIFS and multiple visual tools agree there is a strong relationship between Frequent_Mental_Distress and Frequent_Physical_Distress. We choose to remove Frequent_Physical_Distress and rerun our logistic regression model.


```{r Split Data Into Training and Test }
# Remove Frequent_Physical_Distress from data2
data3 <- data2[,-6] 

# build a training & test data set
samplesize=nrow(data3)
train_percent = .75
train_indices = sample(seq(1,samplesize,length = samplesize),train_percent*samplesize) # get random indices
train = data3[train_indices,] # random training data
test = data3[-train_indices,] # random test data

# check train & test for training bias, shoudl see similar proportions of 0s & 1s in each
summary(train$Obese_Class)
summary(test$Obese_Class)

train.x <- train[,2:ncol(train)]
train.y <- train[,1] # Obese_Class is in column 1
```

Lets use PCA and hierarchical clustering to visualize for any other insights. It is fortunate to already have our data somewhat normalized on a percentage scale. It reduces the scale sensitivity seen with PCA. 

```{r PCA}
pc.result<-prcomp(train.x,scale.=TRUE)
pc.scores<-pc.result$x
pc.scores<-data.frame(pc.scores)
pc.scores$Obese_Class<-train.y

#Loadings for interpretation
pc.result$rotation
```

```{r Scree Plot}
# Scree plot
pc.eigen<-(pc.result$sdev)^2
pc.prop<-pc.eigen/sum(pc.eigen)
pc.cumprop<-cumsum(pc.prop)
plot(1:10,pc.prop,type="l",main="Scree Plot",ylim=c(0,1),xlab="PC #",ylab="Proportion of Variation")
axis(1, seq(1,10,1))
lines(1:10,pc.cumprop,lty=3)

# Cumulative proportion plot
cumulative.prop<-cumsum(pc.eigen/sum(pc.eigen))
plot(1:10,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0.5,1))
points(x=6, y=0.9, type="p", pch=10, col="green")
```

The cumulative plot shows 6 PCs are needed to retain ~90% of the total variation in the data.


```{r Plot some Principal Components}

#Use ggplot2 to plot pc's
ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC3)) +
  geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC4)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC5)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC6)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC2, y = PC3)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC2, y = PC4)) +
  geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC2, y = PC5)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC2, y = PC6)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

```

The PCA plots show some separation but not great separation. 

```{r}
train.x <- as.matrix(train.x) # glmnet requires a matrix 
cvfit <- cv.glmnet(train.x, train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")

# predicted probabilities from logistic model  exp(b)/(1+exp(b))
fit.pred <- predict(cvfit, newx = train.x, type = "response")

#Compare the prediction to the real outcome
head(fit.pred)
head(train.y)
```


glm.fit <- glm(Obese_Class ~ ., data = data2, family = binomial)
summary(glm.fit)

MODEL CHECK



OPEN ACTIONS: 

1. Discuss covariance

AH-Variance looks to be pretty good.  Some_college might be screwing it up a tad bit, but i don't think its cause for concern.  As per heatmaps, We have some correlation with Smoking/Freq Mental distress and drinking/Freq Physical Distress -   (not surprising).  Also, mental/physical stress is heavily correlated. 


SB-After talking to Turner we need to decide what vars to keep from a practical stand pt unless we agree with the stats recommendations.

```{r Log Regression Model_cont}
# reduce data set to include only significant variables
data3 = data2[,c(1:3,5,6,8)]

#Create test/train split
samplesize=nrow(data3)
train_percent = .75
train_indices = sample(seq(1,samplesize,length = samplesize),train_percent*samplesize) # get random indices
train = data3[train_indices,] # random training data
test = data3[-train_indices,] # random test data

# Logistics Regression
glm.fit <- glm(Obese_Class ~ ., data = data3, family = binomial)
summary(glm.fit)
#Confidence Intervals
confint.default(glm.fit) #Wald
confint(glm.fit) #Profile


#odds ratio
exp(cbind(odd = coef(glm.fit), confint(glm.fit)))

#checking group proportions
table(test$Obese_Class)
table(train$Obese_Class)


#Model prediction/Accuracy
glm.pred <- glm.fit %>% predict(test, type = "response")
predicted.classes <-ifelse(glm.pred < 0.3, 0, 1)
observed.classes <- test$Obese_Class
mean(predicted.classes == observed.classes)


```


OPEN ACTIONS: 

1. Create performance metrics
2. Add CIs
3. Explain coefficients
4. Add hypothesis
5. Comment on practical vs statistical significance of significant variables

========================================================================================

OBJECTIVE 2:

With a simple logistic regression model as a baseline, perform additional competing models to improve on prediction performance metrics.

Since PCA is for feature reduction, we will add back all variables except the one with strong collinearity,  Frequent_Physical_Distress. 

OPEN ACTIONS:

1. WITH THE NEW PREDICTORS THE PARAGRAPH BELOW NEEDS TO BE MODIFIED
2. Add comments for observations
3. Add other models (KNN, RANDOM FOREST,...)
4. Add summary comparison table

Judging from the intial scree plot, it looks as though the second Principal component carries just under 90% of the variation.  The main loading coefficients for PC2 were Physically_Inactive, Diabetic, Unemployed, and Severe_Housing_Problems. By far, the largest coefficient was Severe_Housing_Problems (-0.721) which leads us to believe that having consitent residence plays a big part in determining Obesity.


Get Variance Stats

```{r Variance}
round(cov(data2[2:11]), 2) 
sum(diag(cov(data2[2:11]))) # total variance
```

```{r Steve LDA}
samplesize=nrow(data2)
train_percent = .75
train_indices = sample(seq(1,samplesize,length = samplesize),train_percent*samplesize) # get random indices
train = data3[train_indices,] # random training data 
test = data3[-train_indices,] # random test data 

lda <- lda(Obese_Class~.,data = train)
qda <- qda(Obese_Class~.,data = train)

#lda confusion matrix
lda_prd<-predict(lda, newdata = test)$class
lda_cm<-table(lda_prd,test$Obese_Class)
lda_cm

#qda confusion matrix
qda_prd<-predict(qda, newdata = test)$class
qda_cm<-table(qda_prd,test$Obese_Class)
qda_cm

#lda overall misclassification rrror rate
lda_ME<-(lda_cm[2,1]+lda_cm[1,2])/(lda_cm[1,2]+lda_cm[2,2])
lda_ME

#lda Overall Accuracy
1-lda_ME

#qda overall misclassification rrror rate
qda_ME<-(qda_cm[2,1]+qda_cm[1,2])/(qda_cm[1,2]+qda_cm[2,2])
qda_ME

#qda Overall Accuracy
1-qda_ME

#--lda ROC--
ldaprd<-predict(lda, newdata = train)$posterior
#correcting for the way lda creates predicted probabilities
ldaprd<-ldaprd[,2]

pred <- prediction(ldaprd, train$Obese_Class)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

#Plot lda ROC
plot(roc.perf,main="LDA")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .25, y = .75,paste("AUC = ", round(auc.train[[1]],3), sep = ""))

#--qda ROC--
qdaprd<-predict(qda, newdata = train)$posterior
#correcting for the way lda creates predicted probabilities
qdaprd<-qdaprd[,2]

pred <- prediction(qdaprd, train$Obese_Class)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

#Plot lda ROC
plot(roc.perf,main="QDA")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .25, y = .75,paste("AUC = ", round(auc.train[[1]],3), sep = ""))


```

```{r Rando_Forrest}
#Feel free to delete/update/put your own in.  I was just messing around with this and uploaded it for fun.  

#f'ing forrests
#data4 <- data[,c(5,7:18,24:25)]
#Obsese.full.forrest <- randomForest(Obese_Class~., data=data4, importance = TRUE) #importance(rf_model) #Variable importance for placement order (Forward, Backward, Stepwise) 
#varImpPlot(Obsese.full.forrest,type=1, main='Random Tree Variable Importance') 

```

```{r trees setup}
library(rgl)
library(tree)
library(ISLR)
library(randomForest)
```

```{r trees}
#reset dataset
data <- read.csv("./Data/CHR_Data.csv")
#remove the id numbers, need to remove the state and county because that doesn't work with trees
data <- data[,-c(1:3)]
attach(data)
```

```{r repeat adjustment of variables}
# impute variables with their medians, prefer medians in the event there is any skew
data$Premature_Death_Rate <- with(data,impute(Premature_Death_Rate,median)) # may use this later so imputing now
data$Unemployed <- with(data,impute(Unemployed,median))
data$Uninsured <- with(data,impute(Uninsured,median))
data$Graduation_Rate <- with(data,impute(Graduation_Rate))

# rescale Premature_Death_Rate so min value = 2.947 vs 2947, just a preference so it's not scaled so diff from predictors
data$Premature_Death_Rate <- data$Premature_Death_Rate/1000
```

```{r deep tree}
mytree <- tree(Premature_Death_Rate~., data)
plot(mytree)
text(mytree,pretty=0)
```

This tree shows that Frequent Physical Distress is a main split point for premature deaths.

```{r}
#cross validation tree
set.seed(3)
cv.adver=cv.tree(mytree,FUN=prune.tree,method="deviance")
names(cv.adver)
cv.adver
plot(cv.adver)
par(mfrow=c(1,1))
plot(cv.adver$size,cv.adver$dev,type="b")
```

```{r}
#compare normal regression, knn, and ols methods using MSE
set.seed(123)
index<-sample(1:3136,1568)
train<-data[index,]
test<-data[-index,]

train.tree<-tree(Premature_Death_Rate~.,train)
summary(train.tree)
plot(train.tree)
text(train.tree,pretty=0)
plot(cv.tree(train.tree,FUN=prune.tree,method="deviance"))

testMSE<-mean((test$Premature_Death_Rate - predict(train.tree,newdata=test) )^2)


knn<-FNN::knn.reg(train = train[,-c(3,4)], test =test[,-c(3,4)], y = train$Premature_Death_Rate, k = 5)
testMSE.knn<-mean( ( test$Premature_Death_Rate-knn$pred)^2)

full.fit<-lm(Premature_Death_Rate~.,train)
testMSE.ols<-mean((test$Premature_Death_Rate-predict(full.fit,test))^2)


testMSE
testMSE.knn
testMSE.ols
```

The OLS method has the lowest MSE of 1.970053.