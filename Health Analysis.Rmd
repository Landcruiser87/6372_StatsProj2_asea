---
title: "Health Analysis"
author: "asea"
date: "April 4, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(Hmisc)
library(gplots)
library(ggplot2)
library(ROCR)
library(MASS)
library(corrplot)
```

The national dataset used in this study comes from the 2017 County Health Rankings website. Since each state and county have varying populations, we chose to use the data as a percent of the population. The death rate is the age-adjusted Years of Potential Life Lost rate per 100,000.  

OBJECTIVE1

We want to model the probability of being obsese (BMI > 30) for a particular variable. The team has decided to use the following variables as the predictors.The variable data represent the percentage of the population for a specifc US county.

- Smokers
- Physically Incactive
- Excesive Drinking
- Frequent Mental Distress
- Frequent Physical Distress
- Diabetic
- Insufficient Sleep
- Uninsured
- Some College 
- Unemployed
- Severe Housing Problems


```{r EDA Start}
# import health data
data = read.csv("./Data/CHR_Data.csv")

# show data summary to identify variables with missing data
summary(data)
```

The summary statistics show missing values for Premature_Death_Rate, Unemployed, Uninsured, and Graduation_Rate. We will impute the missing data with the median values since some distributions show a little skew when comparing the mean and medians. We will later show the histograms.

```{r EDA Impute}
# impute variables with their medians, prefer medians in the event there is any skew
data$Premature_Death_Rate <- with(data,impute(Premature_Death_Rate,median)) # may use this later so imputing now
data$Unemployed <- with(data,impute(Unemployed,median))
data$Uninsured <- with(data,impute(Uninsured,median))
data$Graduation_Rate <- with(data,impute(Graduation_Rate))

# rescale Premature_Death_Rate so min value = 2.947 vs 2947, just a preference so it's not scaled so diff from predictors
data$Premature_Death_Rate <- data$Premature_Death_Rate/1000
```

The histograms confirm some skew with Frequent_Mental_Distress, Frequent_Physical_Distress,Uninsured, Unemployed, and Severe_Housing_Problems.

```{r EDA Histograms}
# get chosen predictors for EDA
predictors <- data[,c(5,7:13,15:17)]

# histogram of chosen predictors
par(mfrow=c(2,6))
for(i in 1:11) {
    hist(predictors[,i], main=names(predictors)[i])
}
```

OPEN ACTIONS: 

1. Determine if skew is an issue. I don't think it is with our sample size.

AH- Screw transforming!  Its a slight skew, but nothing blatant.  I went hunting for outliers and found some in Diabetic, Uninsured, and Insuffiecient sleep.  But again.  Huge sample size so i'm not sure its worth taking out. 

2. Identify any outliers and handle them if needed.

```{r EDA}
# create Obese Binary Classification
data$Obese_Class <- 1
data[data$Obese < 30, "Obese_Class"] <- 0
data$Obese_Class <- as.factor(as.character(data$Obese_Class))

# -- create new data set with obese_class first --
data2 <- data[,c(25,5,7:13,15:17)]

# scatter matrices, with Obese at the top
pairs(data2[,c(2:6)],col=data$Obese_Class)
pairs(data2[,c(7:11)],col=data$Obese_Class)

# predictor heatmap correlations
cor1 <- cor(data2[,2:6])
cor2 <- cor(data2[,7:11])

heatmap.2(cor1,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("both"), 
          symm=F,symkey=T,symbreaks=T, scale="none",key=T)
heatmap.2(cor2,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("both"), 
          symm=F,symkey=T,symbreaks=T, scale="none",key=T)

#Correlation Plot 
cor3 <- cor(data2_norace[,2:14])
df_corr <-corrplot(cor3, type="upper", addCoef.col = "white", number.digits = 2, number.cex = 0.5, method="square", order="hclust", title="Variable Corr Heatmap",tl.srt=45, tl.cex = 0.8)

```

Get Variance Stats

```{r Variance}
round(cov(data2[2:11]), 2) # remove race
sum(diag(cov(data2[2:11]))) # total variance
```

OPEN ACTIONS: 

1. Discuss heat maps & covariance

AH-Variance looks to be pretty good.  Some_college might be screwing it up a tad bit, but i don't think its cause for concern.  As per heatmaps, We have some correlation with Smoking/Freq Mental distress and drinking/Freq Physical Distress -   (not surprising).  Also, mental/physical stress is heavily correlated. 

```{r Logistic Reg Model}
# Logistics Regression
glm.fit <- glm(Obese_Class ~ ., data = data2, family = binomial)
summary(glm.fit)

```

```{r}
# reduce data set to include only significant variables
data3 = data2[,c(1:3,5,7,9)]

# Logistics Regression
glm.fit <- glm(Obese_Class ~ ., data = data3, family = binomial)
summary(glm.fit)
#Confidence Intervals
confint.default(glm.fit) #Wald
confint(glm.fit) #Profile

#Performance Metrics

```


OPEN ACTIONS: 

1. Create performance metrics
2. Add CIs
3. Explain coefficients
4. Add hypothesis
5. Comment on practical vs statistical significance of significant variables

========================================================================================

OBJECTIVE 2:

With a simple logistic regression model as a baseline, perform additional competing models to improve on prediction performance metrics.

NOTE: I ADDED THE ALL VARIABLES BACK IN FOR PCA ANALYSIS.

For PCA,the variables are all in percentage form (without dividing by 100). This normalization reduces/eliminates the scale sensitivity seen with PCA preventing bias from variables with different scales.
```{r PCA}

# PCA
dat.x <- data2[,2:12]
dat.y <- data2[,1]
pc.result<-prcomp(dat.x,scale.=TRUE)
pc.scores<-pc.result$x
pc.scores<-data.frame(pc.scores)
pc.scores$Obese_Class<-dat.y

#Loadings for interpretation
pc.result$rotation
```

```{r Scree Plot}
#Scree plot
pc.eigen<-(pc.result$sdev)^2
pc.prop<-pc.eigen/sum(pc.eigen)
pc.cumprop<-cumsum(pc.prop)
plot(1:11,pc.prop,type="l",main="Scree Plot",ylim=c(0,1),xlab="PC #",ylab="Proportion of Variation")
axis(1, seq(1,11,1))
lines(1:11,pc.cumprop,lty=3)
```

OPEN ACTIONS:

1. WITH THE NEW PREDICTORS THE PARAGRAPH BELOW NEEDS TO BE MODIFIED
2. Add comments for observations
3. Add other models (KNN, RANDOM FOREST,...)
4. Add summary comparison table

Judging from the intial scree plot, it looks as though the second Principal component carries just under 90% of the variation.  The main loading coefficients for PC2 were Physically_Inactive, Diabetic, Unemployed, and Severe_Housing_Problems. By far, the largest coefficient was Severe_Housing_Problems (-0.721) which leads us to believe that having consitent residence plays a big part in determining Obesity.

```{r Plot some Principal Components}

#Use ggplot2 to plot pc's
ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC3)) +
  geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC4)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC5)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC6)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC7)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC8)) +
  geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC9)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC10)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC11)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

```

```{r Steve LDA}
samplesize=nrow(data2)
train_percent = .75
train_indices = sample(seq(1,samplesize,length = samplesize),train_percent*samplesize) # get random indices
train = data3[train_indices,] # random training data 
test = data3[-train_indices,] # random test data 

lda <- lda(Obese_Class~.,data = train)
qda <- qda(Obese_Class~.,data = train)

#lda confusion matrix
lda_prd<-predict(lda, newdata = test)$class
lda_cm<-table(lda_prd,test$Obese_Class)
lda_cm

#qda confusion matrix
qda_prd<-predict(qda, newdata = test)$class
qda_cm<-table(qda_prd,test$Obese_Class)
qda_cm

#lda overall misclassification rrror rate
lda_ME<-(lda_cm[2,1]+lda_cm[1,2])/(lda_cm[1,2]+lda_cm[2,2])
lda_ME

#lda Overall Accuracy
1-lda_ME

#qda overall misclassification rrror rate
qda_ME<-(qda_cm[2,1]+qda_cm[1,2])/(qda_cm[1,2]+qda_cm[2,2])
qda_ME

#qda Overall Accuracy
1-qda_ME

#--lda ROC--
ldaprd<-predict(lda, newdata = train)$posterior
#correcting for the way lda creates predicted probabilities
ldaprd<-ldaprd[,2]

pred <- prediction(ldaprd, train$Obese_Class)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

#Plot lda ROC
plot(roc.perf,main="LDA")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .25, y = .75,paste("AUC = ", round(auc.train[[1]],3), sep = ""))

#--qda ROC--
qdaprd<-predict(qda, newdata = train)$posterior
#correcting for the way lda creates predicted probabilities
qdaprd<-qdaprd[,2]

pred <- prediction(qdaprd, train$Obese_Class)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

#Plot lda ROC
plot(roc.perf,main="QDA")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .25, y = .75,paste("AUC = ", round(auc.train[[1]],3), sep = ""))


```

```{r Rando_Forrest}
library(randomForest) 
Obsese.full.model <- randomForest(Obese_Class~., data=train, importance = TRUE) #importance(rf_model) #Variable importance for placement order (Forward, Backward, Stepwise) 
varImpPlot(Obsese.full.model,type=1, main='Random Tree Variable Importance') 
set.seed(25) #Used this to sanity check the ASE results


```
