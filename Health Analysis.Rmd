---
title: "Health Analysis"
author: "asea"
date: "April 4, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(Hmisc)
library(gplots)
library(ggplot2)
library(ROCR)
library(MASS)
```

The national dataset used in this study comes from the 2017 County Health Rankings website. Since each state and county have varying populations, we chose to use the data as a percent of the population. The death rate is the age-adjusted Years of Potential Life Lost rate per 100,000.  


```{r EDA Start}
# import health data
data = read.csv("./Data/CHR_Data.csv")

# show data summary to identify variables with missing data
summary(data)

# impute variables with their medians, prefer medians in the event there is any skew
data$Premature_Death_Rate <- with(data,impute(Premature_Death_Rate,median))
data$Unemployed <- with(data,impute(Unemployed,median))
data$Uninsured <- with(data,impute(Uninsured,median))
data$Graduation_Rate <- with(data,impute(Graduation_Rate))

# rescale Premature_Death_Rate so min value = 2.947 vs 2947, just a preference so it's not scaled so diff from predictors
data$Premature_Death_Rate <- data$Premature_Death_Rate/1000

# create Obese Binary Classification
data$Obese_Class <- 1
data[data$Obese < 30, "Obese_Class"] <- 0
data$Obese_Class <- as.factor(as.character(data$Obese_Class))

# add non-white variable
data$NonWhite <- 100-data$White 

#would we want to add a Region variable?   Could do some interesting categorical analysis by region?

# -- create new data set with obese_class first --
data2 <- data[,c(25,5,7:23,26,24)]

# scatter matrices, with Obese at the top
pairs(data2[,c(2:8)],col=data$Obese_Class, main="Personal Physical Condition") # personal physical conditions
pairs(data2[,c(9:14)],col=data$Obese_Class, main = "Education/Living")  # education, living
pairs(data2[,c(15:21)],col=data$Obese_Class, main = "Race/Language") # race, language

# predictor heatmap correlations
cor1 <- cor(data2[,2:8])
cor2 <- cor(data2[,9:14])
cor3 <- cor(data2[,15:21])

heatmap.2(cor1,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("both"), 
          symm=F,symkey=T,symbreaks=T, scale="none",key=T)
heatmap.2(cor2,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("both"), 
          symm=F,symkey=T,symbreaks=T, scale="none",key=T)
heatmap.2(cor3,col=redgreen(75), 
          density.info="none", trace="none", dendrogram=c("both"), 
          symm=F,symkey=T,symbreaks=T, scale="none",key=T)


```

Get Variance Stats...We should rank/sort these
```{r Variance}
cov(data2[2:14]) # remove race
sum(diag(cov(data2[2:14]))) # total variance

```

For PCA,the variables are all in percentage form (without dividing by 100). This normalization reduces/eliminates the scale sensitivity seen with PCA preventing bias from variables with different scales.
```{r PCA}

# let's continue removing race variables
data2_norace <- data2[,1:14]

# PCA
dat.x <- data2_norace[,2:14]
dat.y <- data2_norace[,1]
pc.result<-prcomp(dat.x,scale.=TRUE)
pc.scores<-pc.result$x
pc.scores<-data.frame(pc.scores)
pc.scores$Obese_Class<-dat.y

#Loadings for interpretation
pc.result$rotation
```

```{r Scree Plot}
#Scree plot
pc.eigen<-(pc.result$sdev)^2
pc.prop<-pc.eigen/sum(pc.eigen)
pc.cumprop<-cumsum(pc.prop)
plot(1:13,pc.prop,type="l",main="Scree Plot",ylim=c(0,1),xlab="PC #",ylab="Proportion of Variation")
axis(1, seq(1,13,1))
lines(1:13,pc.cumprop,lty=3)
```

Judging from the intial scree plot, it looks as though the third Principal component carries 90% of the variation.  The main loading coefficients for PC3 were Smoking, Diabetic, Insufficient Sleep, Uninsured, Some college and Rural housing. By far the largest coefficient was Uninsured (.7637) which leads us to believe insurance plays a large part in obesity.


```{r Plot some Principal Components}

#Use ggplot2 to plot pc's
ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC3)) +
  geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC4)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC5)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC6)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC7)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC8)) +
  geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC9)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC10)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC11)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC12)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")

ggplot(data = pc.scores, aes(x = PC1, y = PC13)) +
    geom_point(aes(col=Obese_Class), size=1)+
  geom_hline(yintercept = 0, colour = "gray65") +
    geom_vline(xintercept = 0, colour = "gray65") +
    ggtitle("PCA plot of Health Data")
```

```{r Steve LDA}
samplesize=nrow(data2_norace)
train_percent = .75
train_indices = sample(seq(1,samplesize,length = samplesize),train_percent*samplesize) # get random indices
train = data2_norace[train_indices,] # random training data 
test = data2_norace[-train_indices,] # random test data 

lda <- lda(Obese_Class~.,data = train)
qda <- qda(Obese_Class~.,data = train)

#lda confusion matrix
lda_prd<-predict(lda, newdata = test)$class
lda_cm<-table(lda_prd,test$Obese_Class)
lda_cm

#qda confusion matrix
qda_prd<-predict(qda, newdata = test)$class
qda_cm<-table(qda_prd,test$Obese_Class)
qda_cm

#lda overall misclassification rrror rate
lda_ME<-(lda_cm[2,1]+lda_cm[1,2])/(lda_cm[1,2]+lda_cm[2,2])
lda_ME

#lda Overall Accuracy
1-lda_ME

#qda overall misclassification error rate
qda_ME<-(qda_cm[2,1]+qda_cm[1,2])/(qda_cm[1,2]+qda_cm[2,2])
qda_ME

#qda Overall Accuracy
1-qda_ME

#--lda ROC--
ldaprd<-predict(lda, newdata = train)$posterior
#correcting for the way lda creates predicted probabilities
ldaprd<-ldaprd[,2]

pred <- prediction(ldaprd, train$Obese_Class)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

#Plot lda ROC
plot(roc.perf,main="LDA")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .25, y = .75,paste("AUC = ", round(auc.train[[1]],3), sep = ""))

#--qda ROC--
qdaprd<-predict(qda, newdata = train)$posterior
#correcting for the way lda creates predicted probabilities
qdaprd<-qdaprd[,2]

pred <- prediction(qdaprd, train$Obese_Class)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train <- performance(pred, measure = "auc")
auc.train <- auc.train@y.values

#Plot lda ROC
plot(roc.perf,main="QDA")
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .25, y = .75,paste("AUC = ", round(auc.train[[1]],3), sep = ""))


```

```{r Andy_LDA}
#LDA run with all variables except obesity rating. 
#I should just delete this.  Lol.
library(MASS)
ldadat <- data
ldadat <- ldadat[,4:26] #Takeout id and location data
ldadat <- ldadat[,-3] #Remove obesity column from analysis

obeselda<-lda(Obese_Class~.,data=ldadat) # Run LDA on Obesity Categorical

pred<-predict(obeselda,newdata=ldadat)$class #Yielding categorical obesity response
Tonsoffun<-ldadat$Obese_Class

x<-table(pred,Tonsoffun) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/3136
ME
#Calculating overall accuracy
1-ME

```


